{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Time Series Preprocessing Pipeline Demo\n",
        "\n",
        "This notebook demonstrates how to use the preprocessing pipeline for time series data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path.cwd().parent\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "from preprocessing.config import (\n",
        "    Config, DatasetConfig, PreprocessingConfig,\n",
        "    AugmentationConfig, DataLoaderConfig, TransformConfig\n",
        ")\n",
        "from preprocessing.dataloader.pipeline import TimeSeriesPipeline\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create synthetic time series data\n",
        "n_samples = 100\n",
        "seq_length = 50\n",
        "n_channels = 1\n",
        "\n",
        "# Generate sine waves with different frequencies\n",
        "t = np.linspace(0, 10, seq_length)\n",
        "data = []\n",
        "targets = []\n",
        "\n",
        "for i in range(n_samples):\n",
        "    freq = np.random.uniform(0.5, 2.0)\n",
        "    phase = np.random.uniform(0, 2 * np.pi)\n",
        "    amplitude = np.random.uniform(0.5, 2.0)\n",
        "    \n",
        "    # Add some noise\n",
        "    signal = amplitude * np.sin(2 * np.pi * freq * t + phase)\n",
        "    noise = np.random.normal(0, 0.1, seq_length)\n",
        "    signal = signal + noise\n",
        "    \n",
        "    data.append(signal)\n",
        "    targets.append(freq > 1.25)  # Binary classification based on frequency\n",
        "\n",
        "data = np.array(data).reshape(n_samples, seq_length, n_channels)\n",
        "targets = np.array(targets)\n",
        "\n",
        "# Convert to torch tensors\n",
        "data = torch.FloatTensor(data)\n",
        "targets = torch.LongTensor(targets)\n",
        "\n",
        "# Create a simple dataset\n",
        "from torch.utils.data import TensorDataset\n",
        "dataset = TensorDataset(data, targets)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create pipeline configuration\n",
        "config = Config(\n",
        "    dataset=DatasetConfig(name=\"synthetic\"),\n",
        "    preprocessing=PreprocessingConfig(\n",
        "        transforms=[\n",
        "            TransformConfig(\n",
        "                name=\"MinMaxScaler\",\n",
        "                params={\"feature_range\": [0, 1]}\n",
        "            ),\n",
        "            TransformConfig(\n",
        "                name=\"StandardScaler\",\n",
        "                params={\"epsilon\": 1e-8}\n",
        "            )\n",
        "        ]\n",
        "    ),\n",
        "    augmentation=AugmentationConfig(\n",
        "        enabled=True,\n",
        "        methods=[\"linear_combo\"],\n",
        "        linear_combo_ratio=0.5\n",
        "    ),\n",
        "    dataloader=DataLoaderConfig(\n",
        "        batch_size=32,\n",
        "        shuffle=True\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create pipeline\n",
        "pipeline = TimeSeriesPipeline(config)\n",
        "\n",
        "# Fit transforms\n",
        "pipeline.fit_transforms(dataset)\n",
        "\n",
        "# Create dataloader\n",
        "dataloader = pipeline.create_dataloader(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize original and processed data\n",
        "def plot_samples(original_batch, processed_batch, num_samples=3):\n",
        "    fig, axes = plt.subplots(2, num_samples, figsize=(15, 6))\n",
        "    fig.suptitle('Original vs Processed Time Series')\n",
        "    \n",
        "    for i in range(num_samples):\n",
        "        # Plot original\n",
        "        axes[0, i].plot(original_batch[i, :, 0].numpy())\n",
        "        axes[0, i].set_title(f'Original {i+1}')\n",
        "        axes[0, i].grid(True)\n",
        "        \n",
        "        # Plot processed\n",
        "        axes[1, i].plot(processed_batch[i, :, 0].numpy())\n",
        "        axes[1, i].set_title(f'Processed {i+1}')\n",
        "        axes[1, i].grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Get a batch of data\n",
        "original_batch = next(iter(DataLoader(dataset, batch_size=3, shuffle=True)))[0]\n",
        "processed_batch = next(iter(dataloader))[0]\n",
        "\n",
        "plot_samples(original_batch, processed_batch)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
