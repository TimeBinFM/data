{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc0f7d3c",
   "metadata": {},
   "source": [
    "# Real world example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7291d2db",
   "metadata": {},
   "source": [
    "### Import all libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a7d9049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from typing import List\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "from preprocessing.transform.dataset_builder import Builder\n",
    "from preprocessing.transform.tensor_dataset import TensorIterableDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd9e851",
   "metadata": {},
   "source": [
    "### Create the GiftEval loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d850a9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GiftEvalIterableDataset(TensorIterableDataset):\n",
    "    def __init__(self, repo_id=\"Salesforce/GiftEvalPretrain\", split=\"train\", streaming=True, ts_size=128):\n",
    "        super().__init__()\n",
    "        self.repo_id = repo_id\n",
    "        self.split = split\n",
    "        self.streaming = streaming\n",
    "        self.ts_size = ts_size\n",
    "        \n",
    "        self.test_example = None\n",
    "        self.test_row = None\n",
    "\n",
    "    def __iter__(self):\n",
    "        dataset = iter(load_dataset(self.repo_id, split=self.split, streaming=self.streaming))\n",
    "        while True:\n",
    "            try:\n",
    "                example = next(dataset)\n",
    "                \n",
    "                # to avoid the problems with different shapes of data we only take target into account\n",
    "                # and return on target line at a time\n",
    "                \n",
    "                for row in example[\"target\"]:\n",
    "                    # to avoid different shapes problem\n",
    "                        \n",
    "                    for i in range(len(row) // self.ts_size):\n",
    "                        left = i * self.ts_size\n",
    "                        right = (i + 1) * self.ts_size\n",
    "                        \n",
    "                        if right >= len(row):\n",
    "                            break\n",
    "                            \n",
    "                        ts = row[i * self.ts_size : (i + 1) * self.ts_size]\n",
    "                        \n",
    "                        result = torch.unsqueeze(\n",
    "                            torch.tensor(ts, dtype=torch.float32), \n",
    "                            0\n",
    "                        )\n",
    "                        \n",
    "                        yield torch.nan_to_num(result, nan=0)\n",
    "            except StopIteration:\n",
    "                return\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping example due to error: {e}\")\n",
    "                self.test_example = example\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b092d3",
   "metadata": {},
   "source": [
    "### Create the raw dataset instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b2cbda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_raw = GiftEvalIterableDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c89515c",
   "metadata": {},
   "source": [
    "### Apply post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d20be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def change_random_item_to_avg(batch):\n",
    "    mean = torch.stack(batch, dim=0).mean(dim=0)\n",
    "    \n",
    "    index = rand_index = random.randint(0, len(batch) - 1)\n",
    "    batch[index] = mean\n",
    "    \n",
    "    result = []\n",
    "    for i in range(len(batch)):\n",
    "        if i == index:\n",
    "            result.append(mean)\n",
    "        else:\n",
    "            result.append(batch[i])\n",
    "    \n",
    "    return result\n",
    "\n",
    "def z_transform_tensor_list(tensor_list, eps=1e-8):\n",
    "    # Stack all tensors to compute stats\n",
    "    stacked = torch.cat(tensor_list, dim=1)  # shape: (num_features, total_time)\n",
    "\n",
    "    # Compute mean and std per feature (dim=1 is time, so reduce across it)\n",
    "    mean = stacked.mean(dim=1, keepdim=True)  # shape: (num_features, 1)\n",
    "    std = stacked.std(dim=1, keepdim=True) + eps  # avoid division by zero\n",
    "\n",
    "    # Normalize each tensor\n",
    "    normalized_list = [(t - mean) / std for t in tensor_list]\n",
    "\n",
    "    return normalized_list\n",
    "\n",
    "ds = (\n",
    "    Builder(ds_raw)\n",
    "    .batch(10)\n",
    "    .map(change_random_item_to_avg)\n",
    "    .map(z_transform_tensor_list)\n",
    "    .flat()\n",
    "    .build()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e138833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c985debacc4ae6a4472ce6fd6cb675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/6528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "Skipping example due to error: Couldn't cast array of type\n",
      "list<item: float>\n",
      "to\n",
      "List(List(Value('float32')), length=2)\n",
      "9500\n",
      "\n",
      "Elapsed time: 14.83 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from itertools import islice\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i, item in enumerate(islice(ds, 10_000)):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"\\nElapsed time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fe7d63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
